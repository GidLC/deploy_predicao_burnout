# -*- coding: utf-8 -*-
"""Predição de Burnout (Trabalho Mineração de Dados).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vzcAqAc9FC0ZNsFInYFc2lI1G5LpLwzd

# **Problema de negócio**

# Precisamos prever a taxa de esgotamento dos funcionários com base nos recursos fornecidos, ajudando assim a empresa a tomar as medidas adequadas para saúde mental dos seus colaboradores.

# **Análise Exploratória de Dados**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from datetime import datetime

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/AED Sindrome de Burnout/train.csv")

display(df)

"""Renomeia o titulo das colunas para o português"""

df.rename(columns={'Employee ID' : 'ID', 'Date of Joining': 'Admissao', 'Gender': 'Sexo', 'Company Type': 'Atuacao', 'WFH Setup Available': 'Home_Office','Designation': 'Relevancia', 'Resource Allocation': 'Horas_Trabalhadas', 'Mental Fatigue Score': 'Fadiga_Mental', 'Burn Rate':'Burnout'}, inplace=True)
df.describe()

df.shape

"""# Atribuindo Mediana aos valores Nulos"""

df.isnull().sum()

##Valores atribuidos aos campos nulos das horas trabalhadas
#mediana_horasTrabalhadas = df['Horas Trabalhadas'].median()
#mediana_horasTrabalhadas
#horas = df["Horas Trabalhadas"]
#horas.fillna(mediana_horasTrabalhadas, inplace=True)

##Valores atribuidos aos campos nulos das da fadiga mental
#mediana_fadigaMental = df['Fadiga Mental'].median()
#mediana_fadigaMental
#fadigaMental = df["Fadiga Mental"]
#fadigaMental.fillna(mediana_fadigaMental, inplace= True)

##Valores atribuidos aos campos nulos do Burn Rate
##mediana_burnRate = df['Burn Rate'].median()
##mediana_burnRate
#burnRate = df["Burn Rate"]
#burnRate.fillna(mediana_burnRate, inplace=True)

##Valores atribuidos aos campos nulos das horas trabalhadas(média)
media_horasTrabalhadas = df['Horas_Trabalhadas'].mean()
media_horasTrabalhadas
horas = df["Horas_Trabalhadas"]
##horas.fillna(media_horasTrabalhadas, inplace=True)
horas.fillna(4.0, inplace=True)

##Valores atribuidos aos campos nulos das da fadiga mental (média)
media_fadigaMental = df['Fadiga_Mental'].mean()
media_fadigaMental
fadigaMental = df["Fadiga_Mental"]
fadigaMental.fillna(media_fadigaMental, inplace= True)

#Valores atribuidos aos campos nulos do Burn Rate
media_burnRate = df['Burnout'].mean()
media_burnRate
burnRate = df["Burnout"]
burnRate.fillna(media_burnRate, inplace=True)

df.isnull().sum()

"""###Não há valores duplicados"""

duplicados = df[df.duplicated()]
duplicados

"""# **Estatisticas das váriaveis**"""

## Números de pessoas de acordo com o Sexo
agrupado_sexo = df.groupby('Sexo').size().reset_index(name='qtd')
agrupado_sexo.plot(kind='bar', x='Sexo', y='qtd')
plt.title('Quantidade de Pessoas de acordo com o Sexo')

##Número de pesoas que trabalham ou não em Home Office
agrupado_home = df.groupby('Home_Office').size().reset_index(name='qtd')
agrupado_home.plot(kind='bar', x='Home_Office', y='qtd')
plt.title('Quantidade de Pessoas de acordo com a Home Office')

##Quantidade de Pessoas de acordo com a Atuação
agrupado_atuacao = df.groupby('Atuacao').size().reset_index(name='qtd')
agrupado_atuacao.plot(kind='bar', x='Atuacao', y='qtd')
plt.title('Quantidade de Pessoas de acordo com a Atuacao')

agrupado_relevancia = df.groupby('Relevancia').size().reset_index(name='qtd')
agrupado_relevancia.plot(kind='bar', x='Relevancia', y='qtd')
plt.title('Quantidade de Pessoas de acordo com a Relevancia')

agrupado_horastrabalhadas = df.groupby('Horas_Trabalhadas').size().reset_index(name='qtd')
agrupado_horastrabalhadas.plot(kind='bar', x='Horas_Trabalhadas', y='qtd')
plt.title('Quantidade de Pessoas de acordo com as horas trabalhadas')

agrupado_fadigaMental = df.groupby('Fadiga_Mental').size().reset_index(name='qtd')
agrupado_fadigaMental.plot(kind='bar', x='Fadiga_Mental', y='qtd')
plt.title('Quantidade de Pessoas de acordo com a Fadiga Mental')

##Quantidade de Pessoas de acordo com a Burn Rate
agrupado_burnRate = df.groupby('Burnout').size().reset_index(name='qtd')
agrupado_burnRate.plot(kind='bar', x='Burnout', y='qtd')
plt.title('Quantidade de Pessoas de acordo com a Burn Rate')

"""##BoxPlot's"""

##Não há Outliers
#sns.boxplot(df['Horas Trabalhadas'])

#sns.boxplot(df['Fadiga Mental'])

#df["Outlier"] = np.where(df["Fadiga Mental"] < 2 , True, False)
##df.loc[df["Outlier"] == True, "Fadiga Mental"] = mediana_fadigaMental
#df.loc[df["Outlier"] == True, "Fadiga Mental"] = media_fadigaMental

#sns.boxplot(df['Burn Rate'])

#df.drop(columns='Outlier', axis=1, inplace=False)

#df["Outlier"] = np.where(df["Burn Rate"] > 0.9, True, False)
##df.loc[df["Outlier"] == True, "Burn Rate"] = mediana_burnRate
##df.loc[df["Outlier"] == True, "Burn Rate"] = media_burnRate

#df.drop(columns='Outlier', axis=1, inplace=True)

"""# **-----------------------------------------**

# **Pré-Processamento de Dados**

### LabelEncoder - Variáveis não numéricas

Transformando a Admissão em um objeto DateTime
"""

df['Data'] = pd.to_datetime(df['Admissao'], format='%Y/%m/%d')

df['Dias'] = (datetime.today() - df['Data']).dt.days

df

"""Trabalha em Home Office?

*   Sim: 1
*   Não: 0


"""

df['Home_Office'].replace({"Yes": 1, "No": 0}, inplace=True)

"""Área de Atuação da Empresa:

*   Produtos: 0
*   Serviços: 1


"""

df['Atuacao'].replace({"Service": 1, "Product": 0}, inplace=True)

plt.figure(figsize=(7,3), dpi=100)
sns.distplot(df['Atuacao']).set_title("Indice de Pessoas por Atuação")
plt.show()

"""*   Feminino: 0
*   Masculino: 1


"""

df['Sexo'].replace({"Female": 0, "Male": 1}, inplace=True)

print("###############Fadiga_Mental##################\n")
print(df.corr()['Fadiga_Mental'])
print("###############Relevancia##################\n")
print(df.corr()['Relevancia'])
print("###############Horas_Trabalhadas##################\n")
print(df.corr()['Horas_Trabalhadas'])

rel_sexo_fadiga = df.drop(columns=['ID','Atuacao', 'Home_Office', 'Relevancia', 'Horas_Trabalhadas'], inplace=False)
sexo_agrupado = rel_sexo_fadiga.groupby('Sexo')
media_fadiga_sexo = sexo_agrupado['Burnout'].mean()
media_fadiga_sexo.plot(kind='bar', x='sexo', y='Burnout')
plt.title('Relação entre Sexo e Fadiga Mental')

rel_horas_fadiga = df.drop(columns=['ID','Atuacao', 'Home_Office', 'Relevancia', 'Sexo'], inplace=False)
horas_agrupado = rel_horas_fadiga.groupby('Horas_Trabalhadas')
media_fadiga_horas = horas_agrupado['Burnout'].mean()
media_fadiga_horas.plot(kind='bar', x='Horas_Trabalhadas', y='Burnout')
plt.title('Relação entre Horas Trabalhadas e o Burn Rate')

"""### Eliminando Variáveis que não são explicativas para a previsão"""

df.drop(columns='ID', axis=1, inplace=True)
df.drop(columns='Admissao', axis=1, inplace=True)
df.drop(columns='Data', axis=1, inplace=True)
df.drop(columns='Horas_Trabalhadas', axis=1, inplace=True)
df.drop(columns='Relevancia', axis=1, inplace=True)

df

correlacao = df.corr(method='pearson')
plot = sns.heatmap(df.corr(method='pearson'),  annot = True, fmt=".1f", linewidths=.6)
plot

"""### Criando variável x (alvo) e y (dependente)"""

#y = df.pop("Fadiga Mental")
y = df.pop("Burnout")
X = df

"""### Fazendo a amostragem de dados

Iniciando com train test split
"""

X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state= 42)          #usa 80% dos para treinar e 20% para avaliar;

"""Mostrando os dados de treino e teste"""

print("train data size: ",X_train.shape)
print("test data size: ",X_test.shape)

"""##Construindo a Máquina Preditiva"""

#Construindo
modelo_xgb = xgb.XGBRegressor()

##Treinando
modelo_xgb.fit(X_train, y_train)

y_predict = modelo_xgb.predict(X_test)

"""##Avaliação da Máquina Preditiva

Algoritimo Ciência de Dados
"""

#variaveis_importantes = modelo_xgb.get_booster().get_score(importance_type = 'weight')
#keys = list(variaveis_importantes.keys())
#values = list(variaveis_importantes.values())

#data = pd.DataFrame(data=values, index=keys, columns=["score"]).sort_values(by = "score", ascending = True)
#data.plot(kind='barh')

"""Algoritimo Regressão Linear"""

x = df.iloc[:, 1].values
y = df.iloc[:, 0].values
print(x)
print(y)

"""**Light GBM Regression** 

"""

# Iniciando o Modelo
lg = LGBMRegressor()

# Fit the model
lg.fit(X_train, y_train)

# Realizando predições
lg_y_pred = lg.predict(X_test)

##Métricas de Avaliação
  #R-Quadrado (Quanto maior o valor, melhor)
lr_r2= r2_score(y_test, lg_y_pred)
print("Light GBM Regression R2: ", lr_r2)

  #Raiz do erro quadrático médio (RMSE) (Quanto menor o valor, melhor)
rmse = (np.sqrt(mean_squared_error(y_test,lg_y_pred)))
print("Light GBM Regression RMSE:", rmse)

  #Erro Absoluto Médio (MAE) (Quanto maior o valor, melhor)
MAE = mean_absolute_error(y_test,lg_y_pred)
print("Light GBM Regression MAE:",MAE)

  #Erro Quadrático Médio (MSE) (Quanto menor o valor, melhor)
MSE = mean_squared_error(y_test,lg_y_pred)
print("Light GBM Regression MSE:", MSE)

  #R-Quadrado Ajustado (Quanto maior o valor, melhor)
def adjusted_r2(y_test, y_pred,X_train):
  Adj_r2 = (1 - ((1 - r2_score(y_test, y_pred)) * (len(y_test) - 1)) / 
          (len(y_test) - X_train.shape[1] - 1))
    
  return Adj_r2

print("Light GBM Regression R ajustado:", adjusted_r2(y_test, lg_y_pred, X_train))

"""**Linear Regression** """

# Iniciando o Modelo
lm = LinearRegression()

# Fit the model
lm.fit(X_train, y_train)

# Realizando predições
lm_y_pred = lm.predict(X_test)

##Métricas de Avaliação
  #R-Quadrado (Quanto maior o valor, melhor)
lr_r2= r2_score(y_test, lm_y_pred)
print("Linear Regression R2: ", lr_r2)

  #Raiz do erro quadrático médio (RMSE) (Quanto menor o valor, melhor)
rmse = (np.sqrt(mean_squared_error(y_test,lm_y_pred)))
print("Linear Regression RMSE:", rmse)

  #Erro Absoluto Médio (MAE) (Quanto maior o valor, melhor)
MAE = mean_absolute_error(y_test,lm_y_pred)
print("Linear Regression MAE:",MAE)

  #Erro Quadrático Médio (MSE) (Quanto menor o valor, melhor)
MSE = mean_squared_error(y_test,lm_y_pred)
print("Linear Regression MSE:", MSE)

  #R-Quadrado Ajustado (Quanto maior o valor, melhor)
def adjusted_r2(y_test, y_pred,X_train):
  Adj_r2 = (1 - ((1 - r2_score(y_test, y_pred)) * (len(y_test) - 1)) / 
          (len(y_test) - X_train.shape[1] - 1))
    
  return Adj_r2

print("Linear Regression R ajustado:", adjusted_r2(y_test, lm_y_pred, X_train))

"""**XGB Regression** 

"""

# Iniciando o Modelo
xg = XGBRegressor()

# Fit the model
xg.fit(X_train, y_train)

# Realizando predições
xg_y_pred = xg.predict(X_test)

##Métricas de Avaliação
  #R-Quadrado (Quanto maior o valor, melhor)
lr_r2= r2_score(y_test, xg_y_pred)
print("XGB Regression R2: ", lr_r2)

  #Raiz do erro quadrático médio (RMSE) (Quanto menor o valor, melhor)
rmse = (np.sqrt(mean_squared_error(y_test,xg_y_pred)))
print("XGB Regression RMSE:", rmse)

  #Erro Absoluto Médio (MAE) (Quanto maior o valor, melhor)
MAE = mean_absolute_error(y_test,xg_y_pred)
print("XGB Regression MAE:",MAE)

  #Erro Quadrático Médio (MSE) (Quanto menor o valor, melhor)
MSE = mean_squared_error(y_test,xg_y_pred)
print("XGB Regression MSE:", MSE)

  #R-Quadrado Ajustado (Quanto maior o valor, melhor)
def adjusted_r2(y_test, y_pred,X_train):
  Adj_r2 = (1 - ((1 - r2_score(y_test, y_pred)) * (len(y_test) - 1)) / 
          (len(y_test) - X_train.shape[1] - 1))
    
  return Adj_r2

print("XGB Regression R ajustado:", adjusted_r2(y_test, xg_y_pred, X_train))

"""**KNN Regression**"""

# Iniciando o Modelo
knn = KNeighborsRegressor()

# Fit the model
knn.fit(X_train, y_train)

# Realizando predições
knn_y_pred = knn.predict(X_test)

##Métricas de Avaliação
  #R-Quadrado (Quanto maior o valor, melhor)
lr_r2= r2_score(y_test, knn_y_pred)
print("KNN Regression R2: ", lr_r2)

  #Raiz do erro quadrático médio (RMSE) (Quanto menor o valor, melhor) 
rmse = (np.sqrt(mean_squared_error(y_test,knn_y_pred)))
print("KNN Regression RMSE:", rmse)

  #Erro Absoluto Médio (MAE) (Quanto maior o valor, melhor)
MAE = mean_absolute_error(y_test,knn_y_pred)
print("KNN Regression MAE:",MAE)

  #Erro Quadrático Médio (MSE) (Quanto menor o valor, melhor)
MSE = mean_squared_error(y_test,knn_y_pred)
print("KNN Regression MSE:", MSE)

  #R-Quadrado Ajustado (Quanto maior o valor, melhor)
def adjusted_r2(y_test, y_pred,X_train):
  Adj_r2 = (1 - ((1 - r2_score(y_test, y_pred)) * (len(y_test) - 1)) / 
          (len(y_test) - X_train.shape[1] - 1))
    
  return Adj_r2

print("KNN Regression R ajustado:", adjusted_r2(y_test, knn_y_pred, X_train))

""" **Decision Tree Regression**"""

# Iniciando o Modelo
dt = DecisionTreeRegressor()

# Fit the model
dt.fit(X_train, y_train)

# Realizando predições
dt_y_pred = dt.predict(X_test)

##Métricas de Avaliação
  #R-Quadrado (Quanto maior o valor, melhor)
lr_r2= r2_score(y_test, dt_y_pred)
print("Decision Tree Regression R2: ", lr_r2)

  #Raiz do erro quadrático médio (RMSE) (Quanto menor o valor, melhor)
rmse = (np.sqrt(mean_squared_error(y_test,dt_y_pred)))
print("Decision Tree Regression RMSE:", rmse)

  #Erro Absoluto Médio (MAE) (Quanto maior o valor, melhor)
MAE = mean_absolute_error(y_test,dt_y_pred)
print("Decision Tree Regression MAE:",MAE)

  #Erro Quadrático Médio (MSE) (Quanto menor o valor, melhor)
MSE = mean_squared_error(y_test,dt_y_pred)
print("Decision Tree Regression MSE:", MSE)

  #R-Quadrado Ajustado (Quanto maior o valor, melhor)
def adjusted_r2(y_test, y_pred,X_train):
  Adj_r2 = (1 - ((1 - r2_score(y_test, y_pred)) * (len(y_test) - 1)) / 
          (len(y_test) - X_train.shape[1] - 1))
    
  return Adj_r2

print("Decision Tree Regression R ajustado:", adjusted_r2(y_test, dt_y_pred, X_train))